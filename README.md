# ğŸ“Š A/B Testing Cheatsheet

A/B testing is a controlled experiment comparing two versions (A and B) of a variable (webpage, feature, ad, etc.) to determine which performs better in terms of a given metric (e.g., conversion rate, click-through rate).

---

## ğŸ”¹ Key Terminology

| Term                  | Definition |
|----------------------|------------|
| **Control Group**     | Group exposed to the original version (A). |
| **Variant Group**     | Group exposed to the new version (B). |
| **Hypothesis**        | Prediction about the outcome of the test. |
| **Conversion**        | Desired user action (purchase, signup, click). |
| **Lift**             | Percentage increase/decrease in performance. |
| **P-value**          | Probability of obtaining observed results under null hypothesis. |
| **Statistical Power** | Probability of correctly rejecting the null hypothesis. |

---

## ğŸ”¹ A/B Testing Process

1. **Identify the Objective** â€“ Define the key metric to improve (e.g., conversion rate).
2. **Formulate Hypothesis** â€“ Predict how changes in Version B will impact the metric.
3. **Split the Audience** â€“ Randomly assign users into control (A) and variant (B) groups.
4. **Run the Test** â€“ Expose each group to their respective versions simultaneously.
5. **Measure the Results** â€“ Analyse data using statistical methods.
6. **Draw Conclusions** â€“ Determine if the variant outperforms the control.
7. **Implement Changes** â€“ Deploy Version B if statistically significant.

---

## ğŸ”¹ Statistical Significance

- **P-value Interpretation:**
  - `P-value < 0.05` â†’ Reject the null hypothesis (significant result âœ…).
  - `P-value > 0.05` â†’ Fail to reject the null hypothesis (no significant result âŒ).
- **Confidence Level:**
  - Typically **95%**, meaning a **5% chance of a Type I error (false positive).**
- **Confidence Interval (CI):**
  - Range in which the true difference between A and B lies with **95% confidence**.

---

## ğŸ”¹ Types of A/B Tests

| Test Type         | Description |
|------------------|-------------|
| **Simple A/B Test** | Compares two versions (A and B). |
| **Multivariate Test** | Tests multiple elements at once. |
| **Split URL Test** | Tests different web pages (URLs). |
| **Bandit Testing** | Dynamically allocates traffic based on performance. |

---

## ğŸ”¹ Common A/B Testing Metrics

**ğŸ“Œ Conversion Metrics**
- **Conversion Rate (CR):** `CR = (Conversions / Total Visitors) * 100%`
- **Click-Through Rate (CTR):** `CTR = (Clicks / Impressions) * 100%`
- **Bounce Rate:** Percentage of visitors who leave without interacting.

**ğŸ“Œ Statistical Metrics**
- **P-value:** Tests statistical significance.
- **Confidence Interval (CI):** Estimates the true performance difference.
- **Lift:** `Lift = ((CR_B - CR_A) / CR_A) * 100%`

**ğŸ“Œ Business Metrics**
- **Revenue per Visitor (RPV):** Measures average revenue per user.
- **Customer Lifetime Value (CLV):** Predicts total revenue from a user.

---

## ğŸ”¹ Common Mistakes

âŒ **Insufficient Sample Size** â€“ Small samples may lead to unreliable results.  
âŒ **Stopping Tests Too Early** â€“ Wait for statistical significance before concluding.  
âŒ **Multiple Comparisons Problem** â€“ Testing too many variations increases false positives.  
âŒ **Ignoring Seasonality** â€“ Account for traffic patterns (e.g., weekends vs. weekdays).  
âŒ **Low Statistical Power** â€“ Increases the risk of Type II errors (false negatives).  

---

## ğŸ”¹ A/B Testing Tools

### **ğŸ“Š A/B Testing Platforms**
- **Google Optimise** â€“ Free tool integrated with Google Analytics.
- **Optimizely** â€“ Advanced multivariate testing & personalisation.
- **VWO (Visual Website Optimiser)** â€“ No-code A/B test creation.
- **Unbounce** â€“ Focused on landing page A/B testing.

### **ğŸ“ˆ Statistical Calculators**
- [Evan Millerâ€™s AB Test Calculator](https://www.evanmiller.org/ab-testing/sample-size.html) â€“ Sample size & significance testing.
- [AB Test Guide](https://www.abtestguide.com/) â€“ Online tool for evaluating A/B tests.

---

## ğŸ”¹ Useful Python Libraries for A/B Testing

```bash
pip install pandas scipy statsmodels seaborn matplotlib ab-testing-py
```

### **Example: Conducting a t-test with SciPy**
```python
from scipy import stats

# Conversion data
control = [100, 105, 110, 95, 90]  # Control group conversion rates
variant = [110, 115, 120, 108, 102]  # Variant group conversion rates

# Perform an independent t-test
t_stat, p_value = stats.ttest_ind(control, variant)

print(f"T-statistic: {t_stat}")
print(f"P-value: {p_value}")
```

---

ğŸ“Œ **Author:** [@sarahsufi](https://github.com/sarahsufi)  
 


